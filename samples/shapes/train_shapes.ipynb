{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import piexif\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                                shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y-s),\n",
    "                                (x-s/math.sin(math.radians(60)), y+s),\n",
    "                                (x+s/math.sin(math.radians(60)), y+s),\n",
    "                                ]], dtype=np.int32)\n",
    "            cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height//4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y-s, x-s, y+s, x+s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "\n",
    "ia.seed(1)\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([    \n",
    "    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "    # But we only blur about 50% of all images.\n",
    "    iaa.Sometimes(0.5,\n",
    "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "    ),\n",
    "    # Strengthen or weaken the contrast in each image.\n",
    "    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "    # Add gaussian noise.\n",
    "    # For 50% of all images, we sample the noise once per pixel.\n",
    "    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "    # channel. This can change the color (not only brightness) of the\n",
    "    # pixels.\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "    # Make some images brighter and some darker.\n",
    "    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "    # which can end up changing the color of the images.\n",
    "\n",
    "   \n",
    "], random_order=True) # apply augmenters in random order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/harsh/Mask_RCNN/logs/shapes20190822T1638/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 39s 389ms/step - loss: 1.7899 - rpn_class_loss: 0.0287 - rpn_bbox_loss: 0.6324 - mrcnn_class_loss: 0.4274 - mrcnn_bbox_loss: 0.4255 - mrcnn_mask_loss: 0.2759 - val_loss: 1.8371 - val_rpn_class_loss: 0.0299 - val_rpn_bbox_loss: 1.2174 - val_mrcnn_class_loss: 0.1232 - val_mrcnn_bbox_loss: 0.2754 - val_mrcnn_mask_loss: 0.1911\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 0.9348 - rpn_class_loss: 0.0130 - rpn_bbox_loss: 0.4651 - mrcnn_class_loss: 0.1618 - mrcnn_bbox_loss: 0.1557 - mrcnn_mask_loss: 0.1392 - val_loss: 1.3128 - val_rpn_class_loss: 0.0229 - val_rpn_bbox_loss: 0.8603 - val_mrcnn_class_loss: 0.1456 - val_mrcnn_bbox_loss: 0.1602 - val_mrcnn_mask_loss: 0.1237\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 20s 204ms/step - loss: 0.8530 - rpn_class_loss: 0.0135 - rpn_bbox_loss: 0.4310 - mrcnn_class_loss: 0.1627 - mrcnn_bbox_loss: 0.1235 - mrcnn_mask_loss: 0.1223 - val_loss: 0.9006 - val_rpn_class_loss: 0.0134 - val_rpn_bbox_loss: 0.5883 - val_mrcnn_class_loss: 0.0787 - val_mrcnn_bbox_loss: 0.1310 - val_mrcnn_mask_loss: 0.0892\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 0.8684 - rpn_class_loss: 0.0120 - rpn_bbox_loss: 0.4646 - mrcnn_class_loss: 0.1533 - mrcnn_bbox_loss: 0.1261 - mrcnn_mask_loss: 0.1124 - val_loss: 0.9023 - val_rpn_class_loss: 0.0107 - val_rpn_bbox_loss: 0.5155 - val_mrcnn_class_loss: 0.1280 - val_mrcnn_bbox_loss: 0.1457 - val_mrcnn_mask_loss: 0.1024\n",
      "Epoch 5/10\n",
      " 40/100 [===========>..................] - ETA: 11s - loss: 0.8179 - rpn_class_loss: 0.0121 - rpn_bbox_loss: 0.4269 - mrcnn_class_loss: 0.1423 - mrcnn_bbox_loss: 0.1106 - mrcnn_mask_loss: 0.1260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-15:\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 626, in next_sample\n",
      "    return six.next(_SHARED_SEQUENCES[uid])\n",
      "  File \"/home/harsh/Mask_RCNN/mrcnn/model.py\", line 1714, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/harsh/Mask_RCNN/mrcnn/model.py\", line 1259, in load_image_gt\n",
      "    hooks=imgaug.HooksImages(activator=hook))\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/imgaug/augmenters/meta.py\", line 470, in augment_image\n",
      "    return self.augment_images([image], hooks=hooks)[0]\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/imgaug/augmenters/meta.py\", line 603, in augment_images\n",
      "    hooks=hooks\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/imgaug/augmenters/meta.py\", line 2816, in _augment_images\n",
      "    hooks=hooks\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/imgaug/augmenters/meta.py\", line 601, in augment_images\n",
      "    random_state=ia.copy_random_state(self.random_state),\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/imgaug/imgaug.py\", line 402, in copy_random_state\n",
      "    rs_copy = dummy_random_state()\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/site-packages/imgaug/imgaug.py\", line 376, in dummy_random_state\n",
      "    return np.random.RandomState(1)\n",
      "  File \"mtrand.pyx\", line 101, in numpy.random.mtrand.RandomState.__init__\n",
      "  File \"mt19937.pyx\", line 131, in numpy.random.mt19937.MT19937.__init__\n",
      "  File \"bit_generator.pyx\", line 517, in numpy.random.bit_generator.BitGenerator.__init__\n",
      "  File \"/home/harsh/anaconda3/envs/maskrcnntensorflowgpu/lib/python3.6/abc.py\", line 180, in __instancecheck__\n",
      "    def __instancecheck__(cls, instance):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=10, \n",
    "            layers='heads', augmentation=seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2, \n",
    "            layers=\"all\", augmentation=seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes_with_augmentaion.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
